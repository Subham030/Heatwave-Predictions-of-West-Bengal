{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e397add-4eb0-4b00-b6c3-5a1a975a36de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "946cc3d1-240f-4d38-ad29-ccc872856c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created 1924 sequences\n",
      "Features shape: (1924, 30)\n",
      "Targets shape: (1924, 7)\n",
      "Date range: 1990-04-01 to 2024-06-30\n",
      "Detailed sequence information saved to data_sequence_info.csv\n",
      "Summary information saved to data_summary.txt\n"
     ]
    }
   ],
   "source": [
    "def extract_date_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Extract date from filename for both naming conventions:\n",
    "    - ECMWF_utci_YYYYMMDD_v1.1_con.area-subset.*.csv (1990-2012)\n",
    "    - mrt_with_utci_YYYYMMDD_hourly_stats.csv (2013-2024)\n",
    "    \"\"\"\n",
    "    parts = filename.split('_')\n",
    "    for part in parts:\n",
    "        # Look for 8-digit number that could be a date\n",
    "        if len(part) == 8 and part.isdigit():\n",
    "            try:\n",
    "                return datetime.strptime(part, '%Y%m%d').date()\n",
    "            except ValueError:\n",
    "                continue\n",
    "    raise ValueError(f\"Could not find date in filename: {filename}\")\n",
    "\n",
    "def process_csv(file_path, output_dir, n_days_past, n_days_future):\n",
    "    \"\"\"\n",
    "    Processes a single CSV file: prepares daily UTCI data for time series forecasting.\n",
    "    Assumes CSV has hourly data (0-23) and date is in filename.\n",
    "    \"\"\"\n",
    "    # Extract date from filename\n",
    "    file_date = extract_date_from_filename(os.path.basename(file_path))\n",
    "    \n",
    "    # Load the data\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Calculate daily mean UTCI\n",
    "    daily_utci = data['UTCI_Celsius_mean'].mean()\n",
    "    \n",
    "    return file_date, daily_utci\n",
    "\n",
    "def process_directory(input_dir, output_dir, n_days_past, n_days_future):\n",
    "    \"\"\"\n",
    "    Processes all CSV files in a directory.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Dictionary to store date -> UTCI mapping\n",
    "    daily_values = {}\n",
    "    \n",
    "    # First pass: collect all daily values\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith('.csv') and ('mrt_with_utci' in file_name or 'ECMWF_utci' in file_name):\n",
    "            file_path = os.path.join(input_dir, file_name)\n",
    "            try:\n",
    "                date, utci_mean = process_csv(file_path, output_dir, n_days_past, n_days_future)\n",
    "                daily_values[date] = utci_mean\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_name}: {str(e)}\")\n",
    "    \n",
    "    if not daily_values:\n",
    "        raise ValueError(\"No valid files were processed. Check file naming patterns and directory path.\")\n",
    "    \n",
    "    # Convert to sorted DataFrame\n",
    "    daily_df = pd.DataFrame(\n",
    "        [(date, utci) for date, utci in daily_values.items()],\n",
    "        columns=['date', 'UTCI_mean']\n",
    "    ).sort_values('date')\n",
    "    \n",
    "    # Create sequences\n",
    "    values_utci = daily_df['UTCI_mean'].values\n",
    "    dates = daily_df['date'].values\n",
    "    \n",
    "    X, y = [], []\n",
    "    sequence_info = []\n",
    "    \n",
    "    # Create sequences of past days and future days\n",
    "    for i in range(len(values_utci) - n_days_past - n_days_future + 1):\n",
    "        # Check if dates are consecutive\n",
    "        date_sequence = dates[i:i + n_days_past + n_days_future]\n",
    "        expected_dates = [date_sequence[0] + timedelta(days=x) for x in range(len(date_sequence))]\n",
    "        \n",
    "        if all(actual == expected for actual, expected in zip(date_sequence, expected_dates)):\n",
    "            X.append(values_utci[i:i + n_days_past])\n",
    "            y.append(values_utci[i + n_days_past:i + n_days_past + n_days_future])\n",
    "            \n",
    "            # Store comprehensive date information\n",
    "            sequence_info.append({\n",
    "                'feature_start_date': dates[i],\n",
    "                'feature_end_date': dates[i + n_days_past - 1],\n",
    "                'target_start_date': dates[i + n_days_past],\n",
    "                'target_end_date': dates[i + n_days_past + n_days_future - 1],\n",
    "                'sequence_id': i + 1  # 1-based indexing for easier reference\n",
    "            })\n",
    "    \n",
    "    if not X:\n",
    "        raise ValueError(\"No valid sequences found. Check if you have consecutive daily data.\")\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Save features and targets\n",
    "    base_name = os.path.basename(input_dir)\n",
    "    np.save(os.path.join(output_dir, f\"{base_name}_features.npy\"), X)\n",
    "    np.save(os.path.join(output_dir, f\"{base_name}_targets.npy\"), y)\n",
    "    \n",
    "    # Save comprehensive sequence information\n",
    "    sequence_df = pd.DataFrame(sequence_info)\n",
    "    sequence_df.to_csv(os.path.join(output_dir, f\"{base_name}_sequence_info.csv\"), index=False)\n",
    "    \n",
    "    # Get unique years from the dates (convert dates to strings first for year extraction)\n",
    "    years = sorted(set([d.year for d in daily_df['date']]))\n",
    "    \n",
    "    # Save summary information\n",
    "    with open(os.path.join(output_dir, f\"{base_name}_summary.txt\"), 'w') as f:\n",
    "        f.write(f\"Dataset Summary\\n\")\n",
    "        f.write(f\"==============\\n\\n\")\n",
    "        f.write(f\"Total sequences: {len(X)}\\n\")\n",
    "        f.write(f\"Features shape: {X.shape} (sequences, past_days)\\n\")\n",
    "        f.write(f\"Targets shape: {y.shape} (sequences, future_days)\\n\\n\")\n",
    "        f.write(f\"Date range:\\n\")\n",
    "        f.write(f\"First sequence starts: {sequence_df['feature_start_date'].min()}\\n\")\n",
    "        f.write(f\"Last sequence ends: {sequence_df['target_end_date'].max()}\\n\\n\")\n",
    "        f.write(f\"Features: {n_days_past} days of historical data\\n\")\n",
    "        f.write(f\"Targets: {n_days_future} days of future predictions\\n\")\n",
    "        f.write(f\"\\nProcessed files from years: {years}\")\n",
    "\n",
    "    print(f\"Successfully created {len(X)} sequences\")\n",
    "    print(f\"Features shape: {X.shape}\")\n",
    "    print(f\"Targets shape: {y.shape}\")\n",
    "    print(f\"Date range: {daily_df['date'].min()} to {daily_df['date'].max()}\")\n",
    "    print(f\"Detailed sequence information saved to {base_name}_sequence_info.csv\")\n",
    "    print(f\"Summary information saved to {base_name}_summary.txt\")\n",
    "\n",
    "# Parameters\n",
    "input_directory = 'data'\n",
    "output_directory = 'entire_utci_arrays(30-7)'\n",
    "n_days_past = 30  # Use 30 days of historical data as features\n",
    "n_days_future =15  # Predict next 7 days\n",
    "\n",
    "# Process all files\n",
    "process_directory(input_directory, output_directory, n_days_past, n_days_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0157488b-6f6b-4ee7-8e42-abff24bfcb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (659, 30)\n",
      "First feature set: [29.16583333 30.17708333 30.35833333 28.78833333 26.6775     26.65833333\n",
      " 28.11875    29.57333333 30.66958333 31.34833333 31.23375    31.45875\n",
      " 31.46875    29.73875    29.06416667 28.9175     28.66333333 29.22583333\n",
      " 29.04541667 27.53708333 26.96125    26.79166667 28.70041667 30.15333333\n",
      " 30.94791667 31.62333333 31.35416667 31.69791667 32.55875    32.90916667]\n",
      "Targets shape: (659, 7)\n",
      "First target set: [32.76916667 32.4675     32.0275     30.5625     29.23458333 28.80958333\n",
      " 30.51875   ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "features_path = 'processed_daily_utci_arrays/data_features.npy'\n",
    "targets_path = 'processed_daily_utci_arrays/data_targets.npy'\n",
    "\n",
    "features = np.load(features_path)\n",
    "targets = np.load(targets_path)\n",
    "\n",
    "print(\"Features shape:\", features.shape)\n",
    "print(\"First feature set:\", features[0])\n",
    "print(\"Targets shape:\", targets.shape)\n",
    "print(\"First target set:\", targets[0])\n",
    "# print(len(features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
